---
title: "Week 8: Justice and Representation in Information Systems"
subtitle: "IS 505 Information Organization and Access"
author: 
  - Dr. Manika Lamba
  - Dr. Liliana Giusti Serra
date: '5 March 2024'
format:
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: images/uiuc.png
    css: styles.css
---

## Class Calendar

![](images/calendar.png){fig-align="center"}

##  {.smaller}

::: columns
::: {.column width="50%"}
**`Group A-K (April 2)`**

1.  Avouris, Cassiani

2.  Barrett, Abigail

3.  Boyle, Nora

4.  Brown, Alyssa

5.  Carrithers, Marguerite

6.  Ding, Weiyu

7.  Eggimann, Kelsey

8.  Faro, Anika

9.  Good, Amanda

10. Harper, Evalyn

11. Harrington, KeSean

12. Kedzierski, Haley

13. Kerr-Dennhardt, Delia
:::

::: {.column width="50%"}
**`Group L-S (April 9)`**

1.  Lawless, Jessie
2.  Mason, Chloe
3.  Mullins, Logan
4.  Nagel, Nicole
5.  Parks, Ren
6.  Pihlstrom, Katherine
7.  Quintana, Kari
8.  Ryan, Isabel
9.  Shepherd, Haley
10. Smerz, Allyson
11. Steiner, Madeline
12. Streeter, Olivia
:::
:::

## Today's Class

-   Introduction
-   Lecture
-   Break (10 minutes)
-   Discussion
-   Break (10 minutes)
-   Class activity

## Week 8 Readings

![](images/readings.png){fig-align="center"}

## Digital Trace Data {.smaller}

::: columns
::: {.column width="70%"}
**`Ten common characteristics of big data`**

-   **Big** - *large datasets are a means to an end; they are not an end in themselves*

::: {style="font-size: 60%;"}
*\[Our\] corpus contains over 500 billion words, in English (361 billion), French (45 billion), Spanish (45 billion), German (37 billion), Chinese (13 billion), Russian (35 billion), and Hebrew (2 billion) [(Michel et al., 2011)](https://doi.org/10.1126/science.1199644)*
:::

-   **Always-on** - *helps to identify unexpected events and real-time measurement*

::: {style="font-size: 60%;"}
[*Ceren Budak and Duncan Watts (2015)*](https://doi.org/10.15195/v2.a18) *were able to do more by using the always-on nature of Twitter to study protesters who used Twitter before, during, and after the event. And, they were able to create a comparison group of nonparticipants before, during, and after the event*
:::

-   **Nonreactive** - *Measurement in big data sources is much less likely to change behavior*

::: {style="font-size: 60%;"}
*even though some big data sources are nonreactive, they are not always free of social desirability bias, the tendency for people to want to present themselves in the best possible way*
:::

::: {style="font-size: 60%;"}
:::
:::

::: {.column width="30%"}
[![](images/cover.jpeg){fig-alt="https://www.bitbybitbook.com/en/1st-ed/preface/" fig-align="center"}](https://www.bitbybitbook.com/en/1st-ed/preface/)

First Published in 2019
:::
:::

## Digital Trace Data {.smaller}

-   [**Incomplete**]{style="color: blue;"}  - *No matter how big your big data, it probably doesn’t have the information you want*

::: {style="font-size: 60%;"}
*big data tends to be missing three types of information useful for social research: demographic information about participants, behavior on other platforms, and data to operationalize theoretical constructs*
:::

-   [**Inaccessible**]{style="color: blue;"}  - *Data held by companies and governments are difficult for researchers to access*

-   [**Non-representative**]{style="color: blue;"}  - *Non-representative data are bad for out-of-sample generalizations, but can be quite useful for within-sample comparisons*

- **Drifting** - *Population drift, usage drift, and system drift make it hard to use big data sources to study long-term trends*

- [**Algorithmically confounded**]{style="color: blue;"} - 
[*Behavior in big data systems is not natural; it is driven by the engineering goals of the systems*]{style="color: orange;"}

## Algorithmic Confounding {.smaller}

> *Algorithmic confounding means that we should be cautious about any claim regarding human behavior that comes from a single digital system, no matter how big*

![](images/bias.jpeg){fig-align="center"}

::: footer
Source: https://www.weforum.org/agenda/2021/07/ai-machine-learning-bias-discrimination/
:::

## New Books {.smaller}

::: r-stack
![](images/new.jpeg){.fragment width="250" height="350"} ![](images/new2.jpeg){.fragment width="250" height="350"} ![](images/new3.jpeg){.fragment width="250" height="350"}
![](images/new4.jpeg){.fragment width="250" height="350"}
:::

## Algorithmic Biasness {.smaller}

![](images/bias.png){fig-align="center"}

::: footer
Lamba, M., Madhusudhan, M. (2022). Text Data and Mining Ethics. In: Text Mining for Information Professionals. Springer, Cham. https://doi.org/10.1007/978-3-030-85085-2_11

Read more here: <https://cte.ku.edu/addressing-bias-ai>
:::

## Algorithmic Biasness (Cont.) {.smaller}

-   Algorithms might disseminate social biases against certain groups of sociodemographic factors (such as race, gender, geography)
-   The output of these algorithms is primarily dependent on the [annotated datasets and is sensitive to social bias created by humans]{style="color: blue;"}
-   An algorithm that uses [both text and metadata to learn is likely to be highly biased]{style="color: blue;"} as metadata consists of the author’s nationality, discipline, etc., when compared to an algorithm with text-only data
-   Even with text-only data, algorithms will still learn bias due to the language problems generated by [second-order effects]{style="color: blue;"} for text-based machine learning
-   Additionally, when using chatbots (*such as ChatGPT*) to provide realtime recommendations, the dialogue of chatbot can be modelled with available metadata to adjust the features of the replier in terms of gender, age, and mood *`(Metaphors in HCI)`*

::: footer
Lamba, M., Madhusudhan, M. (2022). Text Data and Mining Ethics. In: Text Mining for Information Professionals. Springer, Cham. https://doi.org/10.1007/978-3-030-85085-2_11
:::

## Ways to Mitigate Biases {.smaller}

-   Understanding how the data was generated
-   Using tools that identify bias in models and algorithms such as `FairML`, `IBM AI Fairness 360`, `Accenture’s “Teach and Test” Methodology,` `Google’s What-If Tool`, and `Microsoft’s Fairlearn`
-   Making the data, process, and outcome open, thus making it transparent and helping us to judge
-   Creating algorithms and standards that can be adapted from one application to another
-   Following the set of standards proposed by the Association for Computing Machinery US Public Policy Council and applying them at every stage in the algorithm creation process
-   Enforcing accountability in policies during [*auditing in pre-and post-processing as well as standardized assessment*]{.underline} as algorithms do not make mistakes, but humans do

::: footer
Lamba, M., Madhusudhan, M. (2022). Text Data and Mining Ethics. In: Text Mining for Information Professionals. Springer, Cham. https://doi.org/10.1007/978-3-030-85085-2_11
:::

## Discussion {.smaller}

Name

Name

-   Take a few minutes to discuss with a neighbor the question of your choice

## In-Class Activity {.smaller}

## Upcoming Deadlines {.smaller}

**`Spring Break: 9-17 March`**

> **Weekly Discussion Post (Week 10):** *`March 17, 2024 (Sunday) by 11:59 PM`*
>
> **Proposal topic for Final Assignment:** *`March 19, 2024 (Tuesday) by 11:59 PM`*

`Start Prepping for:`

-   *Group A-K Final Project Presentation* **(April 2)**
-   *Group L-S Final Project Presentation* **(April 9)**
-   *Professional engagement post* **(April 9)**
-   *Technical learning post* **(April 23)**

## Next Week (Mar 19): Preservation & Accessibility {.smaller}

![](images/week-9.png){fig-align="center"}

## Office Hours

Open Office Hours: **`Mondays 1-2 PM`**; **`Wednesdays 2-3 PM`**

::: columns
::: {.column width="50%"}
**Dr. Manika Lamba**

Email: ***manika\@illinois.edu***
:::

::: {.column width="50%"}
**Dr. Liliana Giusti Serra**

Email: ***lilianag\@illinois.edu***
:::
:::
